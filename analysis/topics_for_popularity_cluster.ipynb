{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### We generated clusters in counting_bibleverses_with_py_collections. Now lets try to find topics"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# see http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction\n",
      "# http://scikit-learn.org/stable/auto_examples/applications/topics_extraction_with_nmf.html\n",
      "import pyes\n",
      "import json\n",
      "from datetime import datetime, timedelta"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 109
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bv_set = json.loads('[\"ephesians 2:8\", \"hebrews 13:16\", \"i_corinthians 13:4\", \"ii_chronicles 15:7\", \"isaiah 32:17\", \"james 1:19\", \"luke 6:27\", \"matthew 21:22\", \"matthew 5:8\", \"philippians 4:13\", \"proverbs 17:28\", \"revelation 1:8\"]')   "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 98
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bv_set, len(bv_set)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 112,
       "text": [
        "([u'ephesians 2:8',\n",
        "  u'hebrews 13:16',\n",
        "  u'i_corinthians 13:4',\n",
        "  u'ii_chronicles 15:7',\n",
        "  u'isaiah 32:17',\n",
        "  u'james 1:19',\n",
        "  u'luke 6:27',\n",
        "  u'matthew 21:22',\n",
        "  u'matthew 5:8',\n",
        "  u'philippians 4:13',\n",
        "  u'proverbs 17:28',\n",
        "  u'revelation 1:8'],\n",
        " 12)"
       ]
      }
     ],
     "prompt_number": 112
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pyes import ES\n",
      "from pyes.query import MatchAllQuery, FilteredQuery, BoolQuery, MatchQuery, TextQuery\n",
      "from pyes.filters import RangeFilter, TermFilter, QueryFilter, ANDFilter\n",
      "from pyes.utils import ESRange, ESRangeOp\n",
      "\n",
      "conn = ES('192.168.117.4:9201')\n",
      "ts_field='created_at_date'\n",
      "start = datetime.now() + timedelta(days=-15)\n",
      "start = start.strftime(\"%Y-%m-%d\")\n",
      "start"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 100,
       "text": [
        "'2014-04-30'"
       ]
      }
     ],
     "prompt_number": 100
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# filter on days\n",
      "def get_text_from_es(bibleverse, start):\n",
      "    q = MatchAllQuery()\n",
      "    filters = []\n",
      "    filters.append(RangeFilter(qrange=ESRangeOp(field=ts_field, op1='gte',value1=start)))\n",
      "    filters.append(TermFilter(field=\"bibleverse\",value=bibleverse))\n",
      "    q = FilteredQuery(MatchAllQuery(), ANDFilter(filters))\n",
      "    q = q.search(size=20)\n",
      "    resultset = conn.search(indices=[\"habakkuk-all\"], doc_types=[\"habakkuk\"], query=q, size=20)\n",
      "    print \"Total results '{}' {} docs\".format(bibleverse, resultset.total)\n",
      "    res = list()\n",
      "    return [r['text'] for r in resultset]\n",
      "                                 \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "SyntaxError",
       "evalue": "invalid syntax (<ipython-input-101-223645853270>, line 10)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-101-223645853270>\"\u001b[1;36m, line \u001b[1;32m10\u001b[0m\n\u001b[1;33m    print \"Total results '{}' {} docs\".format(bibleverse, resultset.total)\u001b[0m\n\u001b[1;37m                                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
       ]
      }
     ],
     "prompt_number": 101
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "corpus = []\n",
      "for bv in bv_set:\n",
      "    ret = get_text_from_es(bv, start)\n",
      "    corpus.append(\" \".join(ret))\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "vectorizer = TfidfVectorizer(min_df=1)\n",
      "tfidf = vectorizer.fit_transform(corpus)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# http://scikit-learn.org/stable/auto_examples/applications/topics_extraction_with_nmf.html\n",
      "from sklearn import decomposition\n",
      "import time\n",
      "from __future__ import print_function\n",
      "\n",
      "n_samples = 1000\n",
      "n_features = 1000\n",
      "n_topics = 10\n",
      "n_top_words = 20\n",
      "\n",
      "# Fit the NMF model\n",
      "print(\"Fitting the NMF model on with n_samples=%d and n_features=%d...\"\n",
      "      % (n_samples, n_features))\n",
      "nmf = decomposition.NMF(n_components=n_topics).fit(tfidf)\n",
      "\n",
      "# Inverse the vectorizer vocabulary to be able\n",
      "feature_names = vectorizer.get_feature_names()\n",
      "\n",
      "for topic_idx, topic in enumerate(nmf.components_):\n",
      "    print(\"Topic #%d:\" % topic_idx)\n",
      "    print(\" \".join([feature_names[i]\n",
      "                    for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
      "    print()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# take 2. use the original example that starts with CountVectorizer\n",
      "\n",
      "# Author: Olivier Grisel <olivier.grisel@ensta.org>\n",
      "# License: BSD 3 clause\n",
      "\n",
      "from __future__ import print_function\n",
      "\n",
      "from time import time\n",
      "from sklearn.feature_extraction import text\n",
      "from sklearn import decomposition\n",
      "from sklearn import datasets\n",
      "\n",
      "n_samples = 1000\n",
      "n_features = 1000\n",
      "n_topics = 1\n",
      "n_top_words = 20\n",
      "\n",
      "# Load the 20 newsgroups dataset and vectorize it using the most common word\n",
      "# frequency with TF-IDF weighting (without top 5% stop words)\n",
      "\n",
      "t0 = time()\n",
      "print(\"Loading dataset and extracting TF-IDF features...\")\n",
      "vectorizer = text.CountVectorizer(max_df=0.95, max_features=n_features)\n",
      "# vectorizer = text.CountVectorizer(max_df=0.95, max_features=n_features, ngram_range=(3,3))\n",
      "counts = vectorizer.fit_transform(corpus[:n_samples])\n",
      "tfidf = text.TfidfTransformer().fit_transform(counts)\n",
      "print(\"done in %0.3fs.\" % (time() - t0))\n",
      "\n",
      "# Fit the NMF model\n",
      "print(\"Fitting the NMF model on with n_samples=%d and n_features=%d...\"\n",
      "      % (n_samples, n_features))\n",
      "nmf = decomposition.NMF(n_components=n_topics).fit(tfidf)\n",
      "print(\"done in %0.3fs.\" % (time() - t0))\n",
      "\n",
      "# Inverse the vectorizer vocabulary to be able\n",
      "feature_names = vectorizer.get_feature_names()\n",
      "\n",
      "for topic_idx, topic in enumerate(nmf.components_):\n",
      "    print(\"Topic #%d:\" % topic_idx)\n",
      "    print(\" \".join([feature_names[i]\n",
      "                    for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
      "    print()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Loading dataset and extracting TF-IDF features...\n",
        "done in 0.007s.\n",
        "Fitting the NMF model on with n_samples=1000 and n_features=1000...\n",
        "done in 0.046s.\n",
        "Topic #0:\n",
        "do 13 who not love god philippians good it through those 16 of your 28 will with sacrifices hebrews well\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 117
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 102
    }
   ],
   "metadata": {}
  }
 ]
}